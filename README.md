# ðŸ¤– Trading_Bot_RL

Simple system for stock trading using Reinforcement Learning as decision-maker. 

Environment and some functions were modified from library [FinRL: Financial Reinforcement Learning](https://github.com/AI4Finance-Foundation/FinRL). 

Currently **works only with SB3 and SB3-contrib**.

## ðŸ¦¾ **Project main features**
- supports both discrete and continious action space RL algorithms
- restoration of training process (from saved model)
- iterative training feature with changable seeds (for systems with low RAM)
- changable custom features for RL (called INDICATORS)
- RL algorithms from [Stable-Baselines-3](https://stable-baselines3.readthedocs.io/en/master/) & [Stable-Baselines-3 Contrib](https://github.com/Stable-Baselines-Team/stable-baselines3-contrib) (PPO LSTM, TRPO, etc.) are available for usage
- works with any Python version >= 3.6

## â›“ **Some requirements**
- Datasets
  - column names - exact names -> ['date', 'open', 'high', 'low', 'close', 'volume']

## ðŸŒ§ **Current build**
- âœ” Simple stock trading 
- - [x] Custom policy networks (RNN, CNN)
- - [x] Resolved problem with gradients in DDPG, TD3, SAC
- - [x] Threshold exploit (risk management)
- - [x] Optuna Tuning
- - [x] Forecasting Model Code
- - [x] Multiple Stock Trading


## ðŸ’» Installation and Running 
Download and run 1 of example codes (via command):
```
!wget https://raw.github.com/asa-eve/Trading_Bot_RL/main/code_examples/main_iterative_training.ipynb
```

## ðŸ“ƒ File Structure
```
Trading_Bot_RL
â”œâ”€â”€ trading_bot_rl (main folder)
â”‚   â”œâ”€â”€ agent.py
â”‚   â”œâ”€â”€ env.py
â”‚   â””â”€â”€ functions
â”‚   	â”œâ”€â”€ callbacks.py
â”‚   	â”œâ”€â”€ data_preprocessing.py
â”‚   	â”œâ”€â”€ env_functions.py
â”‚   	â”œâ”€â”€ yahoodownloader.py
â”‚   	â””â”€â”€ general.py
â”œâ”€â”€ code_examples
â”œâ”€â”€ datasets
â”œâ”€â”€ trained_models
â”œâ”€â”€ setup.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
