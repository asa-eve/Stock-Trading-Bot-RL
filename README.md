# ðŸ¤– Trading_Bot_RL

Simple system for stock trading using Reinforcement Learning as decision-maker. 

Environment and some functions were modified from library [FinRL: Financial Reinforcement Learning](https://github.com/AI4Finance-Foundation/FinRL). 

## ðŸ¦¾ **Project main features**
- simple to install, fast to run, easy to understand
- free choice of agent's action space (discrete or continious)
- RL algorithms from [Stable-Baselines-3](https://stable-baselines3.readthedocs.io/en/master/) & [Stable-Baselines-3 Contrib](https://github.com/Stable-Baselines-Team/stable-baselines3-contrib) (PPO LSTM, TRPO, etc.) are available for usage
- iterative training feature (for systems with low RAM) with changable seeds
- ability to choose your own INDICATORS for RL model features
- no requirement for active updates & works with Python >= 3.6

## â›“ **Some requirements**
- for datasets - presence of next features with exact names ['date', 'open', 'high', 'low', 'close', 'volume']

## ðŸŒ§ **Current progress**
- âœ” Simple stock trading 
- - [x] Optuna hyperparameter tuning added
- - [x] Forecasting model training feature added
- - [x] Multiple stock trading


## ðŸ’» Installation and Running 
Download and run 1 of example codes (via command):
```
!wget https://raw.github.com/asa-eve/Trading_Bot_RL/main/code_examples/main_iterative_training.ipynb
```

## ðŸ“ƒ File Structure
```
Trading_Bot_RL
â”œâ”€â”€ trading_bot_rl (main folder)
â”‚   â”œâ”€â”€ functions
â”‚   	â”œâ”€â”€ callbacks.py
â”‚   	â”œâ”€â”€ data_preprocessing.py
â”‚   	â”œâ”€â”€ env_functions.py
|     â”œâ”€â”€ yahoodownloader.py
â”‚   	â””â”€â”€ general.py
â”‚   â”œâ”€â”€ agent.py
â”‚   â”œâ”€â”€ env.py
â”œâ”€â”€ code_examples
â”‚   â”œâ”€â”€ main_iterative_training.ipynb
â”œâ”€â”€ datasets
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ trained_models
â”‚   â”œâ”€â”€ <model_name>
â”‚   	â”œâ”€â”€ ... 
â”œâ”€â”€ setup.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
