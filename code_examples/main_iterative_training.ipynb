{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7702c32-15d9-401c-a024-d4ce7a4073e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b0ca16-c22e-45df-acbd-babd4a809988",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/asa-eve/Trading_Bot_RL.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eca3e445-920c-48f4-a894-67fad97da74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adm.000\\Anaconda3\\envs\\rl_finance_py38_GPU_torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Path to directory above Trading_Bot_RL on 1 level\n",
    "sys.path.insert(0, f'{os.path.dirname(os.getcwd())}')\n",
    "\n",
    "from trading_bot_rl.agent import *\n",
    "from trading_bot_rl.env import *\n",
    "\n",
    "from trading_bot_rl.functions.general import *\n",
    "from trading_bot_rl.functions.callbacks import *\n",
    "from trading_bot_rl.functions.env_functions import *\n",
    "from trading_bot_rl.functions.data_preprocessing import *\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, CheckpointCallback\n",
    "\n",
    "def env_kwargs_reinit():\n",
    "    return {\n",
    "    \"hmax\": kwarg_hmax,\n",
    "    \"initial_amount\": kwarg_initial_amount,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list, # buy_cost_list[0],\n",
    "    \"sell_cost_pct\": sell_cost_list, #sell_cost_list[0],\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": kwarg_reward_scaling,\n",
    "    \"make_plots\": MAKE_PLOTS,\n",
    "    \"print_verbosity\": VERBOSITY_PRINT,\n",
    "    \"discrete_action_space\": discrete_action_space,\n",
    "    \"seed\": seed_value\n",
    "}\n",
    "    \n",
    "def print_training_info():\n",
    "    print('---')\n",
    "    print('    Training with next initial parameters:')\n",
    "    print('')\n",
    "    print(f\"          Mode - {'normal'*(1-only_forecasts_data) + (' |' * ((df_name_forecasts != None) and (only_forecasts_data != True))) + ' forecasted'*(df_name_forecasts!=None)}\")\n",
    "    print('')\n",
    "    print(f'       Number of Stocks to trade  - {kwarg_hmax}')\n",
    "    print(f'       Initial money amount       - {kwarg_initial_amount}')\n",
    "    print(f'       Commision                  - {kwarg_buy_sell_cost}')\n",
    "    print(f'       Env reward scaling         - {kwarg_reward_scaling}')\n",
    "    print(f\"       discrete action space      - {('No' * (1 - discrete_action_space)) + ('Yes' * (discrete_action_space))}\")\n",
    "    print('')\n",
    "    print(f\"   Training loop from {start_training_episode} to {end_training_episode - 1} (step = {step_training_episodes})\")\n",
    "    print('')\n",
    "    print(f\"       RL model                   - {model_name}\")\n",
    "    print(f\"       Fixed seed                 - {('No' * (1 - fixed_seed)) + ('Yes' * (fixed_seed))}\")\n",
    "    print(f\"       Device                     - {algorithm_parameters['device']}\")\n",
    "    print('')\n",
    "    print(f\"   Data processing info\")\n",
    "    print('')\n",
    "    print(f\"       Valid + Trade              - {int(test_and_valid_pct * 100)} %\") if valid_split else print(f\"       Trade                      - {int(test_and_valid_pct * 100)} %\")\n",
    "    print(f\"       Tech Indicators usage      - {('No' * (1 - dict_args['tech_indicators_usage'])) + ('Yes' * (dict_args['tech_indicators_usage']))}\")\n",
    "    print('')\n",
    "    print('---')\n",
    "    for i in range(3): print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe9375b-f712-4967-8121-f78349dfdb0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f3d5068-b704-4ade-9e7d-ae7073b2adad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models = {}                       # dictionary for 'saving' models\n",
    "last_model_trained = None                 # 'for testing' - takes last trained model as one for test\n",
    "\n",
    "# RL parameters -----------------\n",
    "discrete_action_space = False             # For discrete 'action_space' in env [21 ~ 0.1 step, 11 ~ 0.2 step, etc..]\n",
    "if discrete_action_space: \n",
    "    discrete_actions = 11   \n",
    "\n",
    "VERBOSITY_PRINT = 1                       # in 'episodes' \n",
    "#VERBOSE_INFO_TRAINING = False             # verbosity for 'stable baselines training'\n",
    "#VERBOSITY_PRINT = 1000*(1-VERBOSE_INFO_TRAINING) + 1*VERBOSE_INFO_TRAINING\n",
    "MAKE_PLOTS = False\n",
    "\n",
    "chosen_callback = 'tensorboard'           # 'tensorboard', 'eval', 'checkpoint', None\n",
    "if chosen_callback == 'eval':\n",
    "    eval_freq = 5\n",
    "\n",
    "fixed_seed = True                        # only for replicating results or hyperparameters tuning\n",
    "if fixed_seed: \n",
    "    seed_values = [1]\n",
    "\n",
    "# {\"a2c\": A2C, \"ddpg\": DDPG, \"td3\": TD3, \"sac\": SAC, \"ppo\": PPO, \"trpo\": TRPO, \"lstm_ppo\": RecurrentPPO}\n",
    "model_name = 'lstm_ppo'\n",
    "algorithm_parameters = {\"learning_rate\": 1e-4,\n",
    "                        \"device\": 'cuda',\n",
    "                         }\n",
    "\n",
    "\n",
    "# Threshold parameters -----------------\n",
    "#quantile = None\n",
    "#turbulence_threshold = quantile      # turbulence_threshold_define() to get turbulence\n",
    "#risk_indicator_col = None            # 'vix' column\n",
    "\n",
    "# Env parameters -----------------\n",
    "kwarg_hmax = 100\n",
    "kwarg_initial_amount = 1000000\n",
    "kwarg_reward_scaling = 1e-4              \n",
    "kwarg_buy_sell_cost = 0.001\n",
    "\n",
    "# Iterative Training parameters ------------\n",
    "times_loop_training = 40\n",
    "start_training_episode = 100                                              # start == episode until which to train 'first time'\n",
    "step_training_episodes = start_training_episode                          # step == number of episodes to train afterwards\n",
    "end_training_episode = start_training_episode * times_loop_training + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "454da8be-b2b7-44b9-b0e2-b858d4b770d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "    Training with next initial parameters:\n",
      "\n",
      "          Mode -  forecasted\n",
      "\n",
      "       Number of Stocks to trade  - 100\n",
      "       Initial money amount       - 1000000\n",
      "       Commision                  - 0.001\n",
      "       Env reward scaling         - 0.0001\n",
      "       discrete action space      - No\n",
      "\n",
      "   Training loop from 100 to 4000 (step = 100)\n",
      "\n",
      "       RL model                   - lstm_ppo\n",
      "       Fixed seed                 - Yes\n",
      "       Device                     - cuda\n",
      "\n",
      "   Data processing info\n",
      "\n",
      "       Trade                      - 15 %\n",
      "       Tech Indicators usage      - No\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All features (except 'date' are chosen to by RL feature ---> want to remove something ---> drop with pandas)\n",
    "# Must have column names ('date', 'open', 'close', 'volume', 'high', 'low') ---> use pandas rename your df\n",
    "# -----------------------\n",
    "\n",
    "df_names = ['^GSPC_ta_my_features'] # ['all_ta_features', 'filtered_features', '^GSPC_ta_my_features']\n",
    "df_name_forecasts = '_with_forecasts_LSTM_1_120'            # '_with_forecasts_LSTM_1_120'\n",
    "only_forecasts_data = True\n",
    "unwanted_features = ['date', 'tic']\n",
    "encode_normalize_data = True\n",
    "\n",
    "path_to_datasets = (os.path.dirname(os.getcwd())+'\\\\datasets\\\\').replace(\"\\\\\",\"/\")\n",
    "path_to_models = (os.path.dirname(os.getcwd())+'\\\\trained_models\\\\').replace(\"\\\\\",\"/\")\n",
    "\n",
    "test_and_valid_pct = 0.15\n",
    "valid_split = False\n",
    "BOOL_TO_INT = True\n",
    "\n",
    "dict_args={\n",
    "            \"test_and_valid_pct\": test_and_valid_pct,\n",
    "            \"tic_name\": 'SPY',\n",
    "            \"valid_split\": valid_split,\n",
    "            \"BOOL_TO_INT\": BOOL_TO_INT,\n",
    "            \"tech_indicators_usage\": False,\n",
    "            \"use_vix\": False,\n",
    "            \"use_turbulence\": False,\n",
    "            \"user_defined_feature\": False,\n",
    "}\n",
    "\n",
    "print_training_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4898b-efc0-4ebc-8872-aa355346782d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Iterative Training Process\n",
    "- works with - 'data' & (data, data_with_forecasts)\n",
    "- iterated through all df's (in df_names)\n",
    "    - iterated through all seeds (in seed_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24516010-9188-404e-8124-bd386f13f56f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  1999-03-19   2019-06-06\n",
      "trade  2019-06-07   2022-12-27\n",
      "train  1999-03-19   2019-06-06\n",
      "trade  2019-06-07   2022-12-27\n",
      "Stock Dimension: 1, State Space: 126, State Space Forecasts: 133\n",
      "------\n",
      "------\n",
      "LOOP NUMBER 1 --- 0 EPISODES TRAINED\n",
      "------\n",
      "------\n",
      "{'learning_rate': 0.0001, 'device': 'cuda'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adm.000\\Anaconda3\\envs\\rl_finance_py38_GPU_torch\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 5086, episode: 1\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1821066.69\n",
      "total_reward: 821066.69\n",
      "total_cost: 413519.02\n",
      "total_trades: 4590\n",
      "Sharpe: 0.287\n",
      "=================================\n",
      "day: 5086, episode: 2\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 724453.10\n",
      "total_reward: -275546.90\n",
      "total_cost: 374745.60\n",
      "total_trades: 4275\n",
      "Sharpe: -0.028\n",
      "=================================\n",
      "day: 5086, episode: 3\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1580334.38\n",
      "total_reward: 580334.38\n",
      "total_cost: 349730.58\n",
      "total_trades: 3985\n",
      "Sharpe: 0.221\n",
      "=================================\n",
      "day: 5086, episode: 4\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1158792.91\n",
      "total_reward: 158792.91\n",
      "total_cost: 360179.86\n",
      "total_trades: 3924\n",
      "Sharpe: 0.125\n",
      "=================================\n",
      "day: 5086, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1725827.62\n",
      "total_reward: 725827.62\n",
      "total_cost: 360336.57\n",
      "total_trades: 4098\n",
      "Sharpe: 0.251\n",
      "=================================\n",
      "day: 5086, episode: 6\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1648165.09\n",
      "total_reward: 648165.09\n",
      "total_cost: 231724.89\n",
      "total_trades: 2946\n",
      "Sharpe: 0.227\n",
      "=================================\n",
      "day: 5086, episode: 7\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1068556.68\n",
      "total_reward: 68556.68\n",
      "total_cost: 292701.75\n",
      "total_trades: 3411\n",
      "Sharpe: 0.108\n",
      "=================================\n",
      "day: 5086, episode: 8\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1949498.34\n",
      "total_reward: 949498.34\n",
      "total_cost: 320299.44\n",
      "total_trades: 3821\n",
      "Sharpe: 0.293\n",
      "=================================\n",
      "day: 5086, episode: 9\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1702001.19\n",
      "total_reward: 702001.19\n",
      "total_cost: 285478.77\n",
      "total_trades: 3465\n",
      "Sharpe: 0.238\n",
      "=================================\n",
      "day: 5086, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1343575.65\n",
      "total_reward: 343575.65\n",
      "total_cost: 341072.77\n",
      "total_trades: 3853\n",
      "Sharpe: 0.172\n",
      "=================================\n",
      "day: 5086, episode: 11\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1626842.32\n",
      "total_reward: 626842.32\n",
      "total_cost: 279983.00\n",
      "total_trades: 2947\n",
      "Sharpe: 0.301\n",
      "=================================\n",
      "day: 5086, episode: 12\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1388832.50\n",
      "total_reward: 388832.50\n",
      "total_cost: 301638.93\n",
      "total_trades: 2884\n",
      "Sharpe: 0.188\n",
      "=================================\n",
      "day: 5086, episode: 13\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1566076.63\n",
      "total_reward: 566076.63\n",
      "total_cost: 328817.41\n",
      "total_trades: 3249\n",
      "Sharpe: 0.229\n",
      "=================================\n",
      "day: 5086, episode: 14\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1530240.74\n",
      "total_reward: 530240.74\n",
      "total_cost: 343632.82\n",
      "total_trades: 3505\n",
      "Sharpe: 0.223\n",
      "=================================\n",
      "day: 5086, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1285726.34\n",
      "total_reward: 285726.34\n",
      "total_cost: 354340.35\n",
      "total_trades: 3685\n",
      "Sharpe: 0.158\n",
      "=================================\n",
      "day: 5086, episode: 16\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1689559.72\n",
      "total_reward: 689559.72\n",
      "total_cost: 373156.27\n",
      "total_trades: 4024\n",
      "Sharpe: 0.244\n",
      "=================================\n",
      "day: 5086, episode: 17\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1254093.48\n",
      "total_reward: 254093.48\n",
      "total_cost: 331485.56\n",
      "total_trades: 3681\n",
      "Sharpe: 0.150\n",
      "=================================\n",
      "day: 5086, episode: 18\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1571639.32\n",
      "total_reward: 571639.32\n",
      "total_cost: 344088.42\n",
      "total_trades: 3385\n",
      "Sharpe: 0.222\n",
      "=================================\n",
      "day: 5086, episode: 19\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1646361.83\n",
      "total_reward: 646361.83\n",
      "total_cost: 331261.62\n",
      "total_trades: 3204\n",
      "Sharpe: 0.234\n",
      "=================================\n",
      "day: 5086, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2176552.94\n",
      "total_reward: 1176552.94\n",
      "total_cost: 149128.83\n",
      "total_trades: 1929\n",
      "Sharpe: 0.304\n",
      "=================================\n",
      "day: 5086, episode: 21\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1751423.79\n",
      "total_reward: 751423.79\n",
      "total_cost: 118428.36\n",
      "total_trades: 1456\n",
      "Sharpe: 0.242\n",
      "=================================\n",
      "day: 5086, episode: 22\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1964675.05\n",
      "total_reward: 964675.05\n",
      "total_cost: 170661.94\n",
      "total_trades: 1974\n",
      "Sharpe: 0.275\n",
      "=================================\n",
      "day: 5086, episode: 23\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1622949.37\n",
      "total_reward: 622949.37\n",
      "total_cost: 209773.82\n",
      "total_trades: 2056\n",
      "Sharpe: 0.223\n",
      "=================================\n",
      "day: 5086, episode: 24\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2058691.36\n",
      "total_reward: 1058691.36\n",
      "total_cost: 145991.22\n",
      "total_trades: 1664\n",
      "Sharpe: 0.286\n",
      "=================================\n",
      "day: 5086, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1613466.01\n",
      "total_reward: 613466.01\n",
      "total_cost: 244092.55\n",
      "total_trades: 2658\n",
      "Sharpe: 0.222\n",
      "=================================\n",
      "day: 5086, episode: 26\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1983532.37\n",
      "total_reward: 983532.37\n",
      "total_cost: 265973.79\n",
      "total_trades: 2812\n",
      "Sharpe: 0.280\n",
      "=================================\n",
      "day: 5086, episode: 27\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1581712.02\n",
      "total_reward: 581712.02\n",
      "total_cost: 287230.14\n",
      "total_trades: 2878\n",
      "Sharpe: 0.218\n",
      "=================================\n",
      "day: 5086, episode: 28\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1699268.74\n",
      "total_reward: 699268.74\n",
      "total_cost: 343093.17\n",
      "total_trades: 3288\n",
      "Sharpe: 0.244\n",
      "=================================\n",
      "day: 5086, episode: 29\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1966391.48\n",
      "total_reward: 966391.48\n",
      "total_cost: 332357.81\n",
      "total_trades: 3366\n",
      "Sharpe: 0.283\n",
      "=================================\n",
      "day: 5086, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1473835.01\n",
      "total_reward: 473835.01\n",
      "total_cost: 353782.18\n",
      "total_trades: 3608\n",
      "Sharpe: 0.200\n",
      "=================================\n",
      "day: 5086, episode: 31\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1581810.61\n",
      "total_reward: 581810.61\n",
      "total_cost: 372901.05\n",
      "total_trades: 3978\n",
      "Sharpe: 0.231\n",
      "=================================\n",
      "day: 5086, episode: 32\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1654978.49\n",
      "total_reward: 654978.49\n",
      "total_cost: 343909.96\n",
      "total_trades: 3942\n",
      "Sharpe: 0.235\n",
      "=================================\n",
      "day: 5086, episode: 33\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1919427.96\n",
      "total_reward: 919427.96\n",
      "total_cost: 218263.12\n",
      "total_trades: 2922\n",
      "Sharpe: 0.269\n",
      "=================================\n",
      "day: 5086, episode: 34\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1756277.90\n",
      "total_reward: 756277.90\n",
      "total_cost: 73971.05\n",
      "total_trades: 1167\n",
      "Sharpe: 0.242\n",
      "=================================\n",
      "day: 5086, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1767737.51\n",
      "total_reward: 767737.51\n",
      "total_cost: 90391.73\n",
      "total_trades: 1197\n",
      "Sharpe: 0.244\n",
      "=================================\n",
      "day: 5086, episode: 36\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2158009.71\n",
      "total_reward: 1158009.71\n",
      "total_cost: 84905.88\n",
      "total_trades: 1422\n",
      "Sharpe: 0.298\n",
      "=================================\n",
      "day: 5086, episode: 37\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1856528.13\n",
      "total_reward: 856528.13\n",
      "total_cost: 74341.11\n",
      "total_trades: 1191\n",
      "Sharpe: 0.257\n",
      "=================================\n",
      "day: 5086, episode: 38\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1986943.83\n",
      "total_reward: 986943.83\n",
      "total_cost: 88541.92\n",
      "total_trades: 1238\n",
      "Sharpe: 0.275\n",
      "=================================\n",
      "day: 5086, episode: 39\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1928072.21\n",
      "total_reward: 928072.21\n",
      "total_cost: 73148.35\n",
      "total_trades: 1242\n",
      "Sharpe: 0.267\n",
      "=================================\n",
      "day: 5086, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2056697.40\n",
      "total_reward: 1056697.40\n",
      "total_cost: 65157.43\n",
      "total_trades: 1000\n",
      "Sharpe: 0.284\n",
      "=================================\n",
      "day: 5086, episode: 41\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1944718.75\n",
      "total_reward: 944718.75\n",
      "total_cost: 45481.45\n",
      "total_trades: 770\n",
      "Sharpe: 0.269\n",
      "=================================\n",
      "day: 5086, episode: 42\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1764674.06\n",
      "total_reward: 764674.06\n",
      "total_cost: 30337.42\n",
      "total_trades: 589\n",
      "Sharpe: 0.243\n",
      "=================================\n",
      "day: 5086, episode: 43\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1967112.96\n",
      "total_reward: 967112.96\n",
      "total_cost: 12978.01\n",
      "total_trades: 308\n",
      "Sharpe: 0.272\n",
      "=================================\n",
      "day: 5086, episode: 44\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1843756.12\n",
      "total_reward: 843756.12\n",
      "total_cost: 5109.66\n",
      "total_trades: 91\n",
      "Sharpe: 0.254\n",
      "=================================\n",
      "day: 5086, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1859656.10\n",
      "total_reward: 859656.10\n",
      "total_cost: 4252.83\n",
      "total_trades: 63\n",
      "Sharpe: 0.256\n",
      "=================================\n",
      "day: 5086, episode: 46\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1859842.37\n",
      "total_reward: 859842.37\n",
      "total_cost: 9522.23\n",
      "total_trades: 130\n",
      "Sharpe: 0.256\n",
      "=================================\n",
      "day: 5086, episode: 47\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1815160.45\n",
      "total_reward: 815160.45\n",
      "total_cost: 19635.00\n",
      "total_trades: 282\n",
      "Sharpe: 0.250\n",
      "=================================\n",
      "day: 5086, episode: 48\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1854473.04\n",
      "total_reward: 854473.04\n",
      "total_cost: 8394.02\n",
      "total_trades: 142\n",
      "Sharpe: 0.256\n",
      "=================================\n",
      "day: 5086, episode: 49\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1854582.99\n",
      "total_reward: 854582.99\n",
      "total_cost: 10459.66\n",
      "total_trades: 170\n",
      "Sharpe: 0.256\n",
      "=================================\n",
      "day: 5086, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1957528.99\n",
      "total_reward: 957528.99\n",
      "total_cost: 42198.53\n",
      "total_trades: 634\n",
      "Sharpe: 0.270\n",
      "=================================\n",
      "day: 5086, episode: 51\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1717174.05\n",
      "total_reward: 717174.05\n",
      "total_cost: 136162.99\n",
      "total_trades: 1723\n",
      "Sharpe: 0.237\n",
      "=================================\n",
      "day: 5086, episode: 52\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1682515.30\n",
      "total_reward: 682515.30\n",
      "total_cost: 196862.34\n",
      "total_trades: 2478\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "day: 5086, episode: 53\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1785736.68\n",
      "total_reward: 785736.68\n",
      "total_cost: 109146.09\n",
      "total_trades: 1597\n",
      "Sharpe: 0.247\n",
      "=================================\n",
      "day: 5086, episode: 54\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1746128.52\n",
      "total_reward: 746128.52\n",
      "total_cost: 100003.85\n",
      "total_trades: 1458\n",
      "Sharpe: 0.241\n",
      "=================================\n",
      "day: 5086, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1710320.10\n",
      "total_reward: 710320.10\n",
      "total_cost: 78402.94\n",
      "total_trades: 1249\n",
      "Sharpe: 0.235\n",
      "=================================\n",
      "day: 5086, episode: 56\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1772503.05\n",
      "total_reward: 772503.05\n",
      "total_cost: 46199.35\n",
      "total_trades: 698\n",
      "Sharpe: 0.244\n",
      "=================================\n",
      "day: 5086, episode: 57\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1731241.88\n",
      "total_reward: 731241.88\n",
      "total_cost: 84496.47\n",
      "total_trades: 1317\n",
      "Sharpe: 0.239\n",
      "=================================\n",
      "day: 5086, episode: 58\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1744259.81\n",
      "total_reward: 744259.81\n",
      "total_cost: 90960.02\n",
      "total_trades: 1412\n",
      "Sharpe: 0.242\n",
      "=================================\n",
      "day: 5086, episode: 59\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1472589.51\n",
      "total_reward: 472589.51\n",
      "total_cost: 102572.14\n",
      "total_trades: 1469\n",
      "Sharpe: 0.197\n",
      "=================================\n",
      "day: 5086, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1423887.84\n",
      "total_reward: 423887.84\n",
      "total_cost: 109229.45\n",
      "total_trades: 1495\n",
      "Sharpe: 0.188\n",
      "=================================\n",
      "day: 5086, episode: 61\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 871252.55\n",
      "total_reward: -128747.45\n",
      "total_cost: 174350.91\n",
      "total_trades: 2154\n",
      "Sharpe: 0.033\n",
      "=================================\n",
      "day: 5086, episode: 62\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1732784.25\n",
      "total_reward: 732784.25\n",
      "total_cost: 91706.78\n",
      "total_trades: 1353\n",
      "Sharpe: 0.240\n",
      "=================================\n",
      "day: 5086, episode: 63\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1739657.30\n",
      "total_reward: 739657.30\n",
      "total_cost: 35287.21\n",
      "total_trades: 691\n",
      "Sharpe: 0.240\n",
      "=================================\n",
      "day: 5086, episode: 64\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1673568.61\n",
      "total_reward: 673568.61\n",
      "total_cost: 79739.58\n",
      "total_trades: 1222\n",
      "Sharpe: 0.230\n",
      "=================================\n",
      "day: 5086, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1393794.89\n",
      "total_reward: 393794.89\n",
      "total_cost: 120106.88\n",
      "total_trades: 1724\n",
      "Sharpe: 0.182\n",
      "=================================\n",
      "day: 5086, episode: 66\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1201401.65\n",
      "total_reward: 201401.65\n",
      "total_cost: 176333.73\n",
      "total_trades: 2447\n",
      "Sharpe: 0.139\n",
      "=================================\n",
      "day: 5086, episode: 67\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1481749.68\n",
      "total_reward: 481749.68\n",
      "total_cost: 108949.93\n",
      "total_trades: 1666\n",
      "Sharpe: 0.198\n",
      "=================================\n",
      "day: 5086, episode: 68\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1714954.61\n",
      "total_reward: 714954.61\n",
      "total_cost: 48768.40\n",
      "total_trades: 829\n",
      "Sharpe: 0.236\n",
      "=================================\n",
      "day: 5086, episode: 69\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1765929.91\n",
      "total_reward: 765929.91\n",
      "total_cost: 62992.27\n",
      "total_trades: 990\n",
      "Sharpe: 0.243\n",
      "=================================\n",
      "day: 5086, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1447767.20\n",
      "total_reward: 447767.20\n",
      "total_cost: 180527.69\n",
      "total_trades: 2361\n",
      "Sharpe: 0.192\n",
      "=================================\n",
      "day: 5086, episode: 71\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1588959.31\n",
      "total_reward: 588959.31\n",
      "total_cost: 196553.88\n",
      "total_trades: 2709\n",
      "Sharpe: 0.218\n",
      "=================================\n",
      "day: 5086, episode: 72\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1547545.24\n",
      "total_reward: 547545.24\n",
      "total_cost: 195376.17\n",
      "total_trades: 2665\n",
      "Sharpe: 0.210\n",
      "=================================\n",
      "day: 5086, episode: 73\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1649666.28\n",
      "total_reward: 649666.28\n",
      "total_cost: 160800.87\n",
      "total_trades: 2273\n",
      "Sharpe: 0.227\n",
      "=================================\n",
      "day: 5086, episode: 74\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1286702.46\n",
      "total_reward: 286702.46\n",
      "total_cost: 143579.28\n",
      "total_trades: 1930\n",
      "Sharpe: 0.160\n",
      "=================================\n",
      "day: 5086, episode: 75\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1581033.92\n",
      "total_reward: 581033.92\n",
      "total_cost: 91506.01\n",
      "total_trades: 1381\n",
      "Sharpe: 0.215\n",
      "=================================\n",
      "day: 5086, episode: 76\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1624214.04\n",
      "total_reward: 624214.04\n",
      "total_cost: 112099.86\n",
      "total_trades: 1642\n",
      "Sharpe: 0.222\n",
      "=================================\n",
      "day: 5086, episode: 77\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1602326.57\n",
      "total_reward: 602326.57\n",
      "total_cost: 88535.80\n",
      "total_trades: 1392\n",
      "Sharpe: 0.218\n",
      "=================================\n",
      "day: 5086, episode: 78\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1684706.93\n",
      "total_reward: 684706.93\n",
      "total_cost: 107765.96\n",
      "total_trades: 1382\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "day: 5086, episode: 79\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1736192.09\n",
      "total_reward: 736192.09\n",
      "total_cost: 184108.56\n",
      "total_trades: 2237\n",
      "Sharpe: 0.242\n",
      "=================================\n",
      "day: 5086, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1570849.47\n",
      "total_reward: 570849.47\n",
      "total_cost: 199143.74\n",
      "total_trades: 2390\n",
      "Sharpe: 0.215\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "# For any 'data' in list\n",
    "for df_name in df_names:\n",
    "\n",
    "# Data unpackage + preprocessing\n",
    "    df_main_file = path_to_datasets+f\"{df_name}.csv\"\n",
    "    df_forecasts_file = path_to_datasets+f\"{df_name+df_name_forecasts}.csv\" if (df_name_forecasts != None) else (None)\n",
    "    train_main, valid_main, trade_main, train_forecasts, valid_forecasts, trade_forecasts = data_read_preprocessing_singleTIC(df_main_file, df_forecasts_file, **dict_args)\n",
    "\n",
    "# Defining features (of state_space)\n",
    "    INDICATORS_MAIN = train_main.columns.tolist()\n",
    "    for feature in unwanted_features: \n",
    "        if feature in INDICATORS_MAIN: INDICATORS_MAIN.remove(feature)\n",
    "    if df_forecasts_file != None:\n",
    "        INDICATORS_FORECASTS = train_forecasts.columns.tolist()\n",
    "        for feature in unwanted_features: \n",
    "            if feature in INDICATORS_FORECASTS: INDICATORS_FORECASTS.remove(feature)\n",
    "\n",
    "# RL Env parameters defining\n",
    "    stock_dimension = len(train_main.tic.unique())\n",
    "    state_space_main = 1 + 2*stock_dimension + len(INDICATORS_MAIN)*stock_dimension\n",
    "    state_space_forecasts = 1 + 2*stock_dimension + len(INDICATORS_FORECASTS)*stock_dimension if (df_forecasts_file != None) else (None)\n",
    "    buy_cost_list = sell_cost_list = [kwarg_buy_sell_cost] * stock_dimension\n",
    "    num_stock_shares = [0] * stock_dimension\n",
    "    print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space_main}, State Space Forecasts: {state_space_forecasts}\")\n",
    "\n",
    "    sharpe_forecastFalse = []\n",
    "    sharpe_forecastTrue = []\n",
    "\n",
    "# Main loop (for 'seeds' -> iteratively train 'data' (and if there 'data_with_forecasts') -> save each model and calculate sharpe ->  )\n",
    "    for seed_value in (seed_values*fixed_seed + (1 - fixed_seed) * [None]):\n",
    "        if fixed_seed: set_seed(seed_value)\n",
    "\n",
    "        # Training only 'data' or with 'data_with_forecasts'\n",
    "        is_forecast_list = [False, True] if (df_name_forecasts != None and (not only_forecasts_data)) \\\n",
    "                                                                        else ([False] if (not only_forecasts_data) else ([True] if (only_forecasts_data and df_name_forecasts != None) else []))\n",
    "\n",
    "        for is_forecast in is_forecast_list:\n",
    "\n",
    "            state_space = state_space_forecasts if is_forecast else state_space_main\n",
    "            INDICATORS = INDICATORS_FORECASTS if is_forecast else INDICATORS_MAIN\n",
    "            train = train_forecasts if is_forecast else train_main\n",
    "            trade = trade_forecasts if is_forecast else trade_main\n",
    "            if valid_split: valid = valid_forecasts if is_forecast else valid_main\n",
    "\n",
    "            # Define 'env' parapeters \n",
    "            env_kwargs = env_kwargs_reinit()\n",
    "\n",
    "            # Counter for training (if k=0 -> no model, initialize) ELSE (model = trained)\n",
    "            k=0\n",
    "\n",
    "            # Iterative training loop\n",
    "            for i in range(start_training_episode,end_training_episode,step_training_episodes):\n",
    "                for g in range(2):print('------')\n",
    "                print(f'LOOP NUMBER {int(i/step_training_episodes)} --- {i-start_training_episode} EPISODES TRAINED')\n",
    "                for g in range(2):print('------')\n",
    "                NUM_EPISODES = step_training_episodes \n",
    "                EPISODE_LENGTH = len(train)\n",
    "                NUM_TRAINING_STEPS_FOR_1_TRIAL = NUM_EPISODES * EPISODE_LENGTH \n",
    "\n",
    "                name_of_the_save_file = f\"{path_to_models}{model_name}_techindicators{dict_args['tech_indicators_usage']}_vix{dict_args['use_vix']}_turbulence{dict_args['use_turbulence']}\\\\{df_name}_{model_name}_lr{algorithm_parameters['learning_rate']}_Forecast{is_forecast}_Seed{str(seed_value)*fixed_seed + str(None)*(1-fixed_seed)}_Episodes{i}_Step{step_training_episodes}_Sharpe{valid_split*'Valid' + (1 - valid_split)*'Test'}{int(test_and_valid_pct*100)}\"\n",
    "                name_of_the_save_file_zip = name_of_the_save_file + \".zip\"\n",
    "\n",
    "                # MODEL TRAINING\n",
    "                if not os.path.exists(name_of_the_save_file_zip):\n",
    "                    \n",
    "                    # Initialize env (correcting number of episodes passed)\n",
    "                    e_train_gym, env_train = env_reinit(train, env_kwargs_reinit())\n",
    "                    e_train_gym.episode = i-start_training_episode + 1\n",
    "                    \n",
    "                    # Callback\n",
    "                    if chosen_callback == 'eval':\n",
    "                        callback_arg = EvalCallback(eval_env=env_train, eval_freq=eval_freq, best_model_save_path=name_of_the_save_file+'\\\\eval_callback', log_path=name_of_the_save_file+'\\\\eval_callback', deterministic=True)\n",
    "                    elif chosen_callback == 'tensorboard':\n",
    "                        callback_arg = TensorboardCallback(BaseCallback)\n",
    "                    \n",
    "                    # MODEL TRAINING\n",
    "                    #e_train_gym, env_train = env_reinit(train, env_kwargs_reinit())\n",
    "                    agent = DRLAgent(env = env_train)\n",
    "                    model = agent.get_model(model_name=model_name, model_kwargs = algorithm_parameters, verbose=0, seed=seed_value) if (k == 0) else model.load(prev_name, env = env_train)\n",
    "                    trained = agent.train_model(model=model, \n",
    "                                                    tb_log_name=model_name,\n",
    "                                                    total_timesteps=NUM_TRAINING_STEPS_FOR_1_TRIAL,\n",
    "                                                    callback=callback_arg)\n",
    "\n",
    "                    # CALCULATING sharpe on 'valid / test'\n",
    "                    env_trade_gym, env_trade = env_reinit(valid, env_kwargs_reinit()) if valid_split else env_reinit(trade, env_kwargs_reinit())\n",
    "                    df_account_value, df_actions = DRLAgent.prediction(model=trained, environment = env_trade_gym)\n",
    "                    sharpe = calculate_sharpe(df_account_value)\n",
    "                    sharpe_forecastTrue.append(sharpe) if is_forecast else sharpe_forecastFalse.append(sharpe)\n",
    "\n",
    "                    # MODEL SAVING\n",
    "                    trained.save(name_of_the_save_file_zip)\n",
    "\n",
    "                    prev_name = name_of_the_save_file_zip\n",
    "                    print('Forecasts = ', is_forecast, '| Seed = ', seed_value, '| Num episodes = ', i, f'| Sharpe {valid_split*\"Valid\" + (1 - valid_split)*\"Test\"} = ', sharpe)\n",
    "                    print('---')\n",
    "                    k+=1\n",
    "\n",
    "                # MODEL LOADING + sharpe calculating\n",
    "                else:\n",
    "                    print('Model already exists')\n",
    "                    k+=1\n",
    "\n",
    "                    e_train_gym, env_train = env_reinit(train, env_kwargs_reinit())\n",
    "                    agent = DRLAgent(env = env_train)\n",
    "                    model = agent.get_model(model_name=model_name, model_kwargs = algorithm_parameters, verbose=0, seed=seed_value)\n",
    "                    trained = model.load(name_of_the_save_file, env = env_train)\n",
    "\n",
    "                    env_trade_gym, env_trade = env_reinit(valid, env_kwargs_reinit()) if valid_split else env_reinit(trade, env_kwargs_reinit())\n",
    "                    df_account_value, df_actions = DRLAgent.prediction(model=trained, environment = env_trade_gym)\n",
    "                    sharpe = calculate_sharpe(df_account_value)\n",
    "                    sharpe_forecastTrue.append(sharpe) if is_forecast else sharpe_forecastFalse.append(sharpe)\n",
    "                    \n",
    "                    prev_name = name_of_the_save_file_zip\n",
    "                    print('Forecasts = ', is_forecast, '| Seed = ', seed_value, '| Num episodes = ', i, f'| Sharpe {valid_split*\"Valid\" + (1 - valid_split)*\"Test\"} = ', sharpe)\n",
    "                    print('---')\n",
    "\n",
    "\n",
    "        print('------')\n",
    "        print(df_name)\n",
    "        print('Seed average no forecast = ', np.mean(sharpe_forecastFalse))\n",
    "        print('Seed average with forecast = ', np.mean(sharpe_forecastTrue))\n",
    "        print('------')\n",
    "        print('No forecast = ', sharpe_forecastFalse)\n",
    "        print('With forecast =', sharpe_forecastTrue)\n",
    "        print('------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
