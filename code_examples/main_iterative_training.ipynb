{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7702c32-15d9-401c-a024-d4ce7a4073e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b0ca16-c22e-45df-acbd-babd4a809988",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/asa-eve/Trading_Bot_RL.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "eca3e445-920c-48f4-a894-67fad97da74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Path to directory above Trading_Bot_RL on 1 level\n",
    "sys.path.insert(0, f'{os.path.dirname(os.getcwd())}')\n",
    "\n",
    "from trading_bot_rl.agent import *\n",
    "from trading_bot_rl.env import *\n",
    "\n",
    "from trading_bot_rl.functions.general import *\n",
    "from trading_bot_rl.functions.callbacks import *\n",
    "from trading_bot_rl.functions.env_functions import *\n",
    "from trading_bot_rl.functions.data_preprocessing import *\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "def env_kwargs_reinit():\n",
    "    return {\n",
    "    \"hmax\": kwarg_hmax,\n",
    "    \"initial_amount\": kwarg_initial_amount,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list, # buy_cost_list[0],\n",
    "    \"sell_cost_pct\": sell_cost_list, #sell_cost_list[0],\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": kwarg_reward_scaling,\n",
    "    \"make_plots\": MAKE_PLOTS,\n",
    "    \"print_verbosity\": VERBOSITY_PRINT,\n",
    "    \"discrete_action_space\": discrete_action_space,\n",
    "}\n",
    "\n",
    "def callback(chosen_callback):\n",
    "    if chosen_callback == 'tensorboard':\n",
    "        return TensorboardCallback\n",
    "    elif chosen_callback == 'eval':\n",
    "        return eval_callback\n",
    "    elif chosen_callback == 'checkpoint':\n",
    "        return checkpoint_callback\n",
    "    \n",
    "def print_training_info():\n",
    "    print('---')\n",
    "    print('    Training with next initial parameters:')\n",
    "    print('')\n",
    "    print(f\"          Mode - {'normal'*(1-only_forecasts_data) + (' |' * ((df_name_forecasts != None) and (only_forecasts_data != True))) + ' forecasted'*(df_name_forecasts!=None)}\")\n",
    "    print('')\n",
    "    print(f'       Number of Stocks to trade  - {kwarg_hmax}')\n",
    "    print(f'       Initial money amount       - {kwarg_initial_amount}')\n",
    "    print(f'       Commision                  - {kwarg_buy_sell_cost}')\n",
    "    print(f'       Env reward scaling         - {kwarg_reward_scaling}')\n",
    "    print(f\"       discrete action space      - {('No' * (1 - discrete_action_space)) + ('Yes' * (discrete_action_space))}\")\n",
    "    print('')\n",
    "    print(f\"   Training loop from {start_training_episode} to {end_training_episode - 1} (step = {step_training_episodes})\")\n",
    "    print('')\n",
    "    print(f\"       RL model                   - {model_name}\")\n",
    "    print(f\"       Fixed seed                 - {('No' * (1 - fixed_seed)) + ('Yes' * (fixed_seed))}\")\n",
    "    print(f\"       Device                     - {algorithm_parameters['device']}\")\n",
    "    print('')\n",
    "    print(f\"   Data processing info\")\n",
    "    print('')\n",
    "    print(f\"       Valid + Trade              - {int(test_and_valid_pct * 100)} %\") if valid_split else print(f\"       Trade                      - {int(test_and_valid_pct * 100)} %\")\n",
    "    print(f\"       Tech Indicators usage      - {('No' * (1 - dict_args['tech_indicators_usage'])) + ('Yes' * (dict_args['tech_indicators_usage']))}\")\n",
    "    print('')\n",
    "    print('---')\n",
    "    for i in range(3): print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe9375b-f712-4967-8121-f78349dfdb0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9f3d5068-b704-4ade-9e7d-ae7073b2adad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models = {}                       # dictionary for 'saving' models\n",
    "last_model_trained = None                 # 'for testing' - takes last trained model as one for test\n",
    "\n",
    "# RL parameters -----------------\n",
    "discrete_action_space = False             # For discrete 'action_space' in env [21 ~ 0.1 step, 11 ~ 0.2 step, etc..]\n",
    "if discrete_action_space: \n",
    "    discrete_actions = 11   \n",
    "\n",
    "VERBOSITY_PRINT = 1                       # in 'episodes' \n",
    "#VERBOSE_INFO_TRAINING = False             # verbosity for 'stable baselines training'\n",
    "#VERBOSITY_PRINT = 1000*(1-VERBOSE_INFO_TRAINING) + 1*VERBOSE_INFO_TRAINING\n",
    "MAKE_PLOTS = False\n",
    "\n",
    "chosen_callback = 'tensorboard'           # 'tensorboard', 'eval', 'checkpoint', None\n",
    "if chosen_callback == 'tensorboard': callback_arg = BaseCallback\n",
    "if chosen_callback == 'eval': callback_arg = None\n",
    "if chosen_callback == 'checkpoint': callback_arg = None\n",
    "\n",
    "fixed_seed = True                        # only for replicating results or hyperparameters tuning\n",
    "if fixed_seed: \n",
    "    seed_values = [1]\n",
    "\n",
    "    \n",
    "model_name = 'a2c'\n",
    "algorithm_parameters = {\"learning_rate\": 1e-4,\n",
    "                        \"device\": 'cuda',\n",
    "                         }\n",
    "\n",
    "\n",
    "# Threshold parameters -----------------\n",
    "#quantile = None\n",
    "#turbulence_threshold = quantile      # turbulence_threshold_define() to get turbulence\n",
    "#risk_indicator_col = None            # 'vix' column\n",
    "\n",
    "# Env parameters -----------------\n",
    "kwarg_hmax = 100\n",
    "kwarg_initial_amount = 1000000\n",
    "kwarg_reward_scaling = 1e-4              \n",
    "kwarg_buy_sell_cost = 0.001\n",
    "\n",
    "# Iterative Training parameters ------------\n",
    "times_loop_training = 1\n",
    "start_training_episode = 50                                              # start == episode until which to train 'first time'\n",
    "step_training_episodes = start_training_episode                          # step == number of episodes to train afterwards\n",
    "end_training_episode = start_training_episode * times_loop_training + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "454da8be-b2b7-44b9-b0e2-b858d4b770d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "    Training with next initial parameters:\n",
      "\n",
      "          Mode - normal\n",
      "\n",
      "       Number of Stocks to trade  - 100\n",
      "       Initial money amount       - 1000000\n",
      "       Commision                  - 0.001\n",
      "       Env reward scaling         - 0.0001\n",
      "       discrete action space      - No\n",
      "\n",
      "   Training loop from 50 to 50 (step = 50)\n",
      "\n",
      "       RL model                   - a2c\n",
      "       Fixed seed                 - Yes\n",
      "       Device                     - cuda\n",
      "\n",
      "   Data processing info\n",
      "\n",
      "       Trade                      - 15 %\n",
      "       Tech Indicators usage      - No\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All features (except 'date' are chosen to by RL feature ---> want to remove something ---> drop with pandas)\n",
    "# Must have column names ('date', 'open', 'close', 'volume', 'high', 'low') ---> use pandas rename your df\n",
    "# -----------------------\n",
    "\n",
    "df_names = ['^GSPC_ta_my_features'] # ['all_ta_features', 'filtered_features', '^GSPC_ta_my_features']\n",
    "df_name_forecasts = None            # '_with_forecasts_LSTM_1_120'\n",
    "only_forecasts_data = False\n",
    "unwanted_features = ['date', 'tic']\n",
    "\n",
    "path_to_datasets = (os.path.dirname(os.getcwd())+'\\\\datasets\\\\').replace(\"\\\\\",\"/\")\n",
    "path_to_models = (os.path.dirname(os.getcwd())+'\\\\trained_models\\\\').replace(\"\\\\\",\"/\")\n",
    "\n",
    "test_and_valid_pct = 0.15\n",
    "valid_split = False\n",
    "BOOL_TO_INT = True\n",
    "\n",
    "dict_args={\n",
    "            \"test_and_valid_pct\": test_and_valid_pct,\n",
    "            \"tic_name\": 'SPY',\n",
    "            \"valid_split\": valid_split,\n",
    "            \"BOOL_TO_INT\": BOOL_TO_INT,\n",
    "            \"tech_indicators_usage\": False,\n",
    "            \"use_vix\": False,\n",
    "            \"use_turbulence\": False,\n",
    "            \"user_defined_feature\": False,\n",
    "}\n",
    "\n",
    "print_training_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4898b-efc0-4ebc-8872-aa355346782d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Iterative Training Process\n",
    "- works with - 'data' & (data, data_with_forecasts)\n",
    "- iterated through all df's (in df_names)\n",
    "    - iterated through all seeds (in seed_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "24516010-9188-404e-8124-bd386f13f56f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "train_forecasts  1993-01-29   2018-07-18\n",
      "trade_forecasts  2018-07-19   2023-01-13\n",
      "Stock Dimension: 1, State Space: 134, State Space Forecasts: None\n",
      "{'learning_rate': 0.0001, 'device': 'cuda'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adm.000\\Anaconda3\\envs\\rl_finance_py38_GPU_torch\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 6413, episode: 3\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3174614.43\n",
      "total_reward: 2174614.43\n",
      "total_cost: 475904.93\n",
      "total_trades: 6356\n",
      "Sharpe: 0.415\n",
      "=================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[193], line 65\u001b[0m\n\u001b[0;32m     63\u001b[0m agent \u001b[38;5;241m=\u001b[39m DRLAgent(env \u001b[38;5;241m=\u001b[39m env_train)\n\u001b[0;32m     64\u001b[0m model \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mget_model(model_name\u001b[38;5;241m=\u001b[39mmodel_name, model_kwargs \u001b[38;5;241m=\u001b[39m algorithm_parameters, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, seed\u001b[38;5;241m=\u001b[39mseed_value) \u001b[38;5;28;01mif\u001b[39;00m (k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m trained\n\u001b[1;32m---> 65\u001b[0m trained \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_TRAINING_STEPS_FOR_1_TRIAL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchosen_callback\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback_arg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# CALCULATING sharpe on 'valid / test'\u001b[39;00m\n\u001b[0;32m     71\u001b[0m env_trade_gym, env_trade \u001b[38;5;241m=\u001b[39m env_reinit(valid, env_kwargs_reinit()) \u001b[38;5;28;01mif\u001b[39;00m valid_split \u001b[38;5;28;01melse\u001b[39;00m env_reinit(trade, env_kwargs_reinit())\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\Trading_Bot_RL\\trading_bot_rl\\agent.py:60\u001b[0m, in \u001b[0;36mDRLAgent.train_model\u001b[1;34m(self, model, tb_log_name, total_timesteps, callback)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, tb_log_name, total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m, callback\u001b[38;5;241m=\u001b[39mTensorboardCallback()):\n\u001b[1;32m---> 60\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl_finance_py38_GPU_torch\\lib\\site-packages\\stable_baselines3\\a2c\\a2c.py:190\u001b[0m, in \u001b[0;36mA2C.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfA2C,\n\u001b[0;32m    183\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    189\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfA2C:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl_finance_py38_GPU_torch\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:267\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mrecord(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime/total_timesteps\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps, exclude\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdump(step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps)\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\rl_finance_py38_GPU_torch\\lib\\site-packages\\stable_baselines3\\a2c\\a2c.py:175\u001b[0m, in \u001b[0;36mA2C.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mrecord(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/n_updates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_updates, exclude\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mrecord(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/explained_variance\u001b[39m\u001b[38;5;124m\"\u001b[39m, explained_var)\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mrecord(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/entropy_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mentropy_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mrecord(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/policy_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, policy_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mrecord(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/value_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, value_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For any 'data' in list\n",
    "for df_name in df_names:\n",
    "\n",
    "# Data unpackage + preprocessing\n",
    "    df_main_file = path_to_datasets+f\"{df_name}.csv\"\n",
    "    df_forecasts_file = path_to_datasets+f\"{df_name+df_name_forecasts}.csv\" if (df_name_forecasts != None) else (None)\n",
    "    train_main, valid_main, trade_main, train_forecasts, valid_forecasts, trade_forecasts = data_read_preprocessing_singleTIC(df_main_file, df_forecasts_file, **dict_args)\n",
    "\n",
    "# Defining features (of state_space)\n",
    "    INDICATORS_MAIN = train_main.columns.tolist()\n",
    "    for feature in unwanted_features: INDICATORS_MAIN.remove(feature)\n",
    "    if df_forecasts_file != None:\n",
    "        INDICATORS_FORECASTS = train_forecasts.columns.tolist()\n",
    "        for feature in unwanted_features:INDICATORS_FORECASTS.remove(feature)\n",
    "\n",
    "# RL Env parameters defining\n",
    "    stock_dimension = len(train_main.tic.unique())\n",
    "    state_space_main = 1 + 2*stock_dimension + len(INDICATORS_MAIN)*stock_dimension\n",
    "    state_space_forecasts = 1 + 2*stock_dimension + len(INDICATORS_FORECASTS)*stock_dimension if (df_forecasts_file != None) else (None)\n",
    "    buy_cost_list = sell_cost_list = [kwarg_buy_sell_cost] * stock_dimension\n",
    "    num_stock_shares = [0] * stock_dimension\n",
    "    print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space_main}, State Space Forecasts: {state_space_forecasts}\")\n",
    "\n",
    "    sharpe_forecastFalse = []\n",
    "    sharpe_forecastTrue = []\n",
    "\n",
    "# Main loop (for 'seeds' -> iteratively train 'data' (and if there 'data_with_forecasts') -> save each model and calculate sharpe ->  )\n",
    "    for seed_value in (seed_values*fixed_seed + (1 - fixed_seed) * [None]):\n",
    "        if fixed_seed: set_seed(seed_value)\n",
    "\n",
    "        # Training only 'data' or with 'data_with_forecasts'\n",
    "        is_forecast_list = [False, True] if (df_name_forecasts != None and (not only_forecasts_data)) \\\n",
    "                                                                        else ([False] if (not only_forecasts_data) else ([True] if (only_forecasts_data and df_name_forecasts != None) else []))\n",
    "\n",
    "        for is_forecast in is_forecast_list:\n",
    "\n",
    "            state_space = state_space_forecasts if is_forecast else state_space_main\n",
    "            INDICATORS = INDICATORS_FORECASTS if is_forecast else INDICATORS_MAIN\n",
    "            train = train_forecasts if is_forecast else train_main\n",
    "            trade = trade_forecasts if is_forecast else trade_main\n",
    "            if valid_split: valid = valid_forecasts if is_forecast else valid_main\n",
    "\n",
    "            # Define 'env' parapeters\n",
    "            env_kwargs = env_kwargs_reinit()\n",
    "\n",
    "            # Counter for training (if k=0 -> no model, initialize) ELSE (model = trained)\n",
    "            k=0\n",
    "\n",
    "            # Iterative training loop\n",
    "            for i in range(start_training_episode,end_training_episode,step_training_episodes):\n",
    "                NUM_EPISODES = i \n",
    "                EPISODE_LENGTH = len(train)\n",
    "                NUM_TRAINING_STEPS_FOR_1_TRIAL = NUM_EPISODES * EPISODE_LENGTH \n",
    "\n",
    "                name_of_the_save_file = f\"{path_to_models}{model_name}_techindicators{dict_args['tech_indicators_usage']}_vix{dict_args['use_vix']}_turbulence{dict_args['use_turbulence']}\\\\{df_name}_{model_name}_lr{algorithm_parameters['learning_rate']}_Forecast{is_forecast}_Seed{str(seed_value)*fixed_seed + str(None)*(1-fixed_seed)}_Episodes{NUM_EPISODES}_Sharpe{valid_split*'Valid' + (1 - valid_split)*'Test'}{int(test_and_valid_pct*100)}\"\n",
    "                name_of_the_save_file_zip = name_of_the_save_file + \".zip\"\n",
    "\n",
    "                # MODEL TRAINING\n",
    "                if not os.path.exists(name_of_the_save_file_zip):\n",
    "\n",
    "                    # MODEL TRAINING\n",
    "                    e_train_gym, env_train = env_reinit(train, env_kwargs_reinit())\n",
    "                    agent = DRLAgent(env = env_train)\n",
    "                    model = agent.get_model(model_name=model_name, model_kwargs = algorithm_parameters, verbose=0, seed=seed_value) if (k == 0) else trained\n",
    "                    trained = agent.train_model(model=model, \n",
    "                                                    tb_log_name=model_name,\n",
    "                                                    total_timesteps=NUM_TRAINING_STEPS_FOR_1_TRIAL,\n",
    "                                                    callback=callback(chosen_callback)(callback_arg))\n",
    "\n",
    "                    # CALCULATING sharpe on 'valid / test'\n",
    "                    env_trade_gym, env_trade = env_reinit(valid, env_kwargs_reinit()) if valid_split else env_reinit(trade, env_kwargs_reinit())\n",
    "                    df_account_value, df_actions = DRLAgent.prediction(model=trained, environment = env_trade_gym)\n",
    "                    sharpe = calculate_sharpe(df_account_value)\n",
    "                    sharpe_forecastTrue.append(sharpe) if is_forecast else sharpe_forecastFalse.append(sharpe)\n",
    "\n",
    "                    # MODEL SAVING\n",
    "                    trained.save(name_of_the_save_file_zip)\n",
    "\n",
    "                    print('Forecasts = ', is_forecast, '| Seed = ', seed_value, '| Num episodes = ', i, f'| Sharpe {valid_split*\"Valid\" + (1 - valid_split)*\"Test\"} = ', sharpe)\n",
    "                    print('---')\n",
    "                    k+=1\n",
    "\n",
    "                # MODEL LOADING + sharpe calculating\n",
    "                else:\n",
    "                    print('Model already exists')\n",
    "                    k+=1\n",
    "\n",
    "                    e_train_gym, env_train = env_reinit(train, env_kwargs_reinit())\n",
    "                    agent = DRLAgent(env = env_train)\n",
    "                    model = agent.get_model(model_name=model_name, model_kwargs = algorithm_parameters, verbose=0, seed=seed_value)\n",
    "                    trained = model.load(name_of_the_save_file, env = env_train)\n",
    "\n",
    "                    env_trade_gym, env_trade = env_reinit(valid, env_kwargs_reinit()) if valid_split else env_reinit(trade, env_kwargs_reinit())\n",
    "                    df_account_value, df_actions = DRLAgent.prediction(model=trained, environment = env_trade_gym)\n",
    "                    sharpe = calculate_sharpe(df_account_value)\n",
    "                    sharpe_forecastTrue.append(sharpe) if is_forecast else sharpe_forecastFalse.append(sharpe)\n",
    "\n",
    "                    print('Forecasts = ', is_forecast, '| Seed = ', seed_value, '| Num episodes = ', i, f'| Sharpe {valid_split*\"Valid\" + (1 - valid_split)*\"Test\"} = ', sharpe)\n",
    "                    print('---')\n",
    "\n",
    "\n",
    "        print('------')\n",
    "        print(df_name)\n",
    "        print('Seed average no forecast = ', np.mean(sharpe_forecastFalse))\n",
    "        print('Seed average with forecast = ', np.mean(sharpe_forecastTrue))\n",
    "        print('------')\n",
    "        print('No forecast = ', sharpe_forecastFalse)\n",
    "        print('With forecast =', sharpe_forecastTrue)\n",
    "        print('------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
