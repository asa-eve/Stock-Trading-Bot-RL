{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7702c32-15d9-401c-a024-d4ce7a4073e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8af20f2c-ef92-48c4-8af0-9a5e79cf2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Path to directory above Trading_Bot_RL on 1 level\n",
    "sys.path.insert(0, f'{os.path.dirname(os.getcwd())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eca3e445-920c-48f4-a894-67fad97da74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install 'shimmy>=0.2.1\n",
    "#!pip install git+https://github.com/optuna/optuna.git\n",
    "#!pip install git+https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
    "\n",
    "from trading_bot_rl.agent import *\n",
    "from trading_bot_rl.env import *\n",
    "\n",
    "from trading_bot_rl.functions.general import *\n",
    "from trading_bot_rl.functions.callbacks import *\n",
    "from trading_bot_rl.functions.env_functions import *\n",
    "from trading_bot_rl.functions.data_preprocessing import *\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import os\n",
    "\n",
    "def env_kwargs_reinit():\n",
    "    return {\n",
    "    \"hmax\": kwarg_hmax,\n",
    "    \"initial_amount\": kwarg_initial_amount,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list, # buy_cost_list[0],\n",
    "    \"sell_cost_pct\": sell_cost_list, #sell_cost_list[0],\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": kwarg_reward_scaling,\n",
    "    \"make_plots\": MAKE_PLOTS,\n",
    "    \"print_verbosity\": VERBOSITY_PRINT,\n",
    "    \"discrete_action_space\": discrete_action_space,\n",
    "}\n",
    "\n",
    "def callback(chosen_callback):\n",
    "    if chosen_callback == 'tensorboard':\n",
    "        return TensorboardCallback\n",
    "    elif chosen_callback == 'eval':\n",
    "        return eval_callback\n",
    "    elif chosen_callback == 'checkpoint':\n",
    "        return checkpoint_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe9375b-f712-4967-8121-f78349dfdb0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f3d5068-b704-4ade-9e7d-ae7073b2adad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models = {}                       # dictionary for 'saving' models\n",
    "last_model_trained = None                 # 'for testing' - takes last trained model as one for test\n",
    "\n",
    "# RL parameters -----------------\n",
    "discrete_action_space = False             # For discrete 'action_space' in env [21 ~ 0.1 step, 11 ~ 0.2 step, etc..]\n",
    "if discrete_action_space: \n",
    "    discrete_actions = 11   \n",
    "\n",
    "VERBOSITY_PRINT = 1                       # in 'episodes' \n",
    "#VERBOSE_INFO_TRAINING = False             # verbosity for 'stable baselines training'\n",
    "#VERBOSITY_PRINT = 1000*(1-VERBOSE_INFO_TRAINING) + 1*VERBOSE_INFO_TRAINING\n",
    "MAKE_PLOTS = False\n",
    "\n",
    "chosen_callback = 'tensorboard'           # 'tensorboard', 'eval', 'checkpoint', None\n",
    "if chosen_callback == 'tensorboard': callback_arg = BaseCallback\n",
    "if chosen_callback == 'eval': callback_arg = None\n",
    "if chosen_callback == 'checkpoint': callback_arg = None\n",
    "\n",
    "fixed_seed = True                        # only for replicating results or hyperparameters tuning\n",
    "if fixed_seed: \n",
    "    seed_values = [1]\n",
    "    \n",
    "model_name = 'a2c'\n",
    "algorithm_parameters = {\"learning_rate\": 1e-4,\n",
    "                        \"device\": 'cuda',\n",
    "                         }\n",
    "\n",
    "turbulence_threshold = None\n",
    "risk_indicator_col = None\n",
    "quantile = 0.997\n",
    "# 'vix' column\n",
    "# turbulence_threshold_define() to get turbulence\n",
    "\n",
    "# Env parameters -----------------\n",
    "kwarg_hmax = 100\n",
    "kwarg_initial_amount = 1000000\n",
    "kwarg_reward_scaling = 1e-4              \n",
    "kwarg_buy_sell_cost = 0.001\n",
    "\n",
    "# Iterative Training parameters ------------\n",
    "resume_training = False                     # resume training from already existing model  \n",
    "times = 1\n",
    "start_training_episode = 50                                 # start == episode until which to train 'first time'\n",
    "step_training_episodes = start_training_episode             # step == number of episodes to train afterwards\n",
    "end_training_episode = start_training_episode * times + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454da8be-b2b7-44b9-b0e2-b858d4b770d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All features (except 'date' are chosen to by RL feature ---> want to remove something ---> drop with pandas)\n",
    "# Must have column names ('date', 'open', 'close', 'volume', 'high', 'low') ---> use pandas rename your df\n",
    "\n",
    "# Big problem was with 'data_split' ---> it ate last element from 'train', 'valid', 'end'\n",
    "\n",
    "# -----------------------\n",
    "\n",
    "df_names = ['^GSPC_ta_my_features'] # ['all_ta_features', 'filtered_features', '^GSPC_ta_my_features']\n",
    "df_name_forecasts = None # '_with_forecasts_LSTM_1_120'\n",
    "unwanted_features = ['date', 'tic']\n",
    "\n",
    "path_to_datasets = os.getcwd()+'\\\\Trading_bot_RL\\\\datasets\\\\'\n",
    "path_to_models = os.getcwd()+'\\\\Trading_bot_RL\\\\trained_models\\\\'\n",
    "\n",
    "test_and_valid_pct = 0.15\n",
    "valid_split = False\n",
    "BOOL_TO_INT = True\n",
    "\n",
    "dict_args={\n",
    "            \"test_and_valid_pct\": test_and_valid_pct,\n",
    "            \"tic_name\": 'SPY',\n",
    "            \"valid_split\": valid_split,\n",
    "            \"BOOL_TO_INT\": BOOL_TO_INT,\n",
    "            \"tech_indicators_usage\": True,\n",
    "            \"use_vix\": False,\n",
    "            \"use_turbulence\": False,\n",
    "            \"user_defined_feature\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4898b-efc0-4ebc-8872-aa355346782d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Iterative Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24516010-9188-404e-8124-bd386f13f56f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for df_name in df_names:\n",
    "    \n",
    "    df_main_file = path_to_datasets+f\"{df_name}.csv\"\n",
    "    \n",
    "    if df_name_forecasts == None:\n",
    "        #data.append(df_forecasts_file)\n",
    "        df_forecasts_file = None\n",
    "        if valid_split:\n",
    "            train_main, valid_main, trade_main = data_read_preprocessing_singleTIC(df_main_file, df_forecasts_file, **dict_args)\n",
    "        else:\n",
    "            train_main, trade_main = data_read_preprocessing_singleTIC(df_main_file, df_forecasts_file, **dict_args)\n",
    "    else:\n",
    "        df_forecasts_file = path_to_datasets+f\"{df_name+df_name_forecasts}.csv\"\n",
    "        if valid_split:\n",
    "            train_main, valid_main, trade_main, train_forecasts, valid_forecasts, trade_forecasts = data_read_preprocessing_singleTIC(df_main_file, df_forecasts_file, **dict_args)\n",
    "        else:\n",
    "            train_main, trade_main, train_forecasts, trade_forecasts = data_read_preprocessing_singleTIC(df_main_file, df_forecasts_file, **dict_args)\n",
    "            \n",
    "    INDICATORS_MAIN = train_main.columns.tolist()\n",
    "    for feature in unwanted_features: INDICATORS_MAIN.remove(feature)\n",
    "    if df_forecasts_file != None:\n",
    "        INDICATORS_FORECASTS = train_forecasts.columns.tolist()\n",
    "        for feature in unwanted_features:INDICATORS_FORECASTS.remove(feature)\n",
    "\n",
    "    stock_dimension = len(train_main.tic.unique())\n",
    "    state_space_main = 1 + 2*stock_dimension + len(INDICATORS_MAIN)*stock_dimension\n",
    "    \n",
    "    if df_forecasts_file != None: state_space_forecasts = 1 + 2*stock_dimension + len(INDICATORS_FORECASTS)*stock_dimension\n",
    "    else: state_space_forecasts = None\n",
    "        \n",
    "    buy_cost_list = sell_cost_list = [kwarg_buy_sell_cost] * stock_dimension\n",
    "    num_stock_shares = [0] * stock_dimension\n",
    "    print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space_main}, State Space Forecasts: {state_space_forecasts}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    sharpe_forecastFalse = []\n",
    "    sharpe_forecastTrue = []\n",
    "    \n",
    "\n",
    "    if not resume_training:\n",
    "        for seed_value in (seed_values*fixed_seed + (1 - fixed_seed) * [1]):\n",
    "            if fixed_seed: set_seed(seed_value)\n",
    "            \n",
    "            is_forecast_list = [False]\n",
    "            if df_name_forecasts != None: is_forecast_list.append(True)\n",
    "            for is_forecast in is_forecast_list:\n",
    "                \n",
    "                if is_forecast:\n",
    "                    state_space = state_space_forecasts\n",
    "                    INDICATORS = INDICATORS_FORECASTS\n",
    "                    train = train_forecasts\n",
    "                    trade = trade_forecasts\n",
    "                    if valid_split: valid = valid_forecasts\n",
    "                else:\n",
    "                    state_space = state_space_main\n",
    "                    INDICATORS = INDICATORS_MAIN\n",
    "                    train = train_main\n",
    "                    trade = trade_main\n",
    "                    if valid_split: valid = valid_main\n",
    "\n",
    "                env_kwargs = env_kwargs_reinit()\n",
    "\n",
    "                for i in range(start_training_episode,end_training_episode,step_training_episodes):\n",
    "                    NUM_EPISODES = i \n",
    "                    EPISODE_LENGTH = len(train)\n",
    "                    NUM_TRAINING_STEPS_FOR_1_TRIAL = NUM_EPISODES * EPISODE_LENGTH \n",
    "\n",
    "# STOPPED HERE ---------\n",
    "                    \n",
    "                    name_of_the_save_file = f\"{path_to_models}{model_name}_techindicators{dict_args['tech_indicators_usage']}_vix{dict_args['use_vix']}_turbulence{dict_args['use_turbulence']}\\\\{df_name}_{model_name}_lr{algorithm_parameters['learning_rate']}_Forecast{is_forecast}_Seed{str(seed_value)*fixed_seed + str(None)*(1-fixed_seed)}_Episodes{NUM_EPISODES}_Sharpe{valid_split*'Valid' + (1 - valid_split)*'Test'}{int(test_and_valid_pct*100)}\"\n",
    "                    name_of_the_save_file_zip = name_of_the_save_file + \".zip\"\n",
    "\n",
    "                    if not os.path.exists(name_of_the_save_file_zip):\n",
    "\n",
    "                        e_train_gym, env_train = env_reinit(train, env_kwargs_reinit())\n",
    "                        agent = DRLAgent(env = env_train)\n",
    "\n",
    "\n",
    "                        model = agent.get_model(model_name=model_name, model_kwargs = algorithm_parameters, verbose=0, seed=seed_value)\n",
    "\n",
    "                        trained = agent.train_model(model=model, \n",
    "                                                        tb_log_name=model_name,\n",
    "                                                        total_timesteps=NUM_TRAINING_STEPS_FOR_1_TRIAL,\n",
    "                                                        callback=callback(chosen_callback)(callback_arg))\n",
    "\n",
    "                        if valid_split:\n",
    "                            if turbulence_threshold_usage:\n",
    "                                env_trade_gym, env_trade = env_reinit(valid, env_kwargs_reinit(), turbulence_threshold_define(train, quantile), 'vix')\n",
    "                            else:\n",
    "                                env_trade_gym, env_trade = env_reinit(valid, env_kwargs_reinit())\n",
    "\n",
    "                        else: \n",
    "                            if turbulence_threshold_usage:\n",
    "                                env_trade_gym, env_trade = env_reinit(trade, env_kwargs_reinit(), turbulence_threshold_define(train, quantile), 'vix')\n",
    "                            else:\n",
    "                                env_trade_gym, env_trade = env_reinit(trade, env_kwargs_reinit())\n",
    "                                \n",
    "                        df_account_value, df_actions = DRLAgent.prediction(model=trained, environment = env_trade_gym)\n",
    "\n",
    "                        sharpe = calculate_sharpe(df_account_value)\n",
    "\n",
    "                        trained.save(name_of_the_save_file_zip)\n",
    "\n",
    "                        print('Forecasts = ', is_forecast, '| Seed = ', seed_value, '| Num episodes = ', i, f'| Sharpe {valid_split*\"Valid\" + (1 - valid_split)*\"Test\"} = ', sharpe)\n",
    "                        print('---')\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        print('Model already exists')\n",
    "\n",
    "                        agent = DRLAgent(env = env_train)\n",
    "                        model = agent.get_model(model_name=model_name, model_kwargs = algorithm_parameters, verbose=0, seed=seed_value)\n",
    "                        trained = model.load(name_of_the_save_file)\n",
    "\n",
    "                        if valid_split:\n",
    "                            if turbulence_threshold != None:\n",
    "                                env_trade_gym, env_trade = env_reinit(valid, env_kwargs_reinit(), turbulence_threshold_define(train, quantile), 'vix')\n",
    "                            else:\n",
    "                                env_trade_gym, env_trade = env_reinit(valid, env_kwargs_reinit())\n",
    "\n",
    "                        else: \n",
    "                            if turbulence_threshold != None:\n",
    "                                env_trade_gym, env_trade = env_reinit(trade, env_kwargs_reinit(), turbulence_threshold_define(train, quantile), 'vix')\n",
    "                            else:\n",
    "                                env_trade_gym, env_trade = env_reinit(trade, env_kwargs_reinit())\n",
    "\n",
    "                        df_account_value, df_actions = DRLAgent.prediction(model=trained, environment = env_trade_gym)\n",
    "                        sharpe = calculate_sharpe(df_account_value)\n",
    "\n",
    "                        if not is_forecast: sharpe_forecastFalse.append(sharpe)\n",
    "                        else: sharpe_forecastTrue.append(sharpe)\n",
    "\n",
    "                        print('Forecasts = ', is_forecast, '| Seed = ', seed_value, '| Num episodes = ', i, f'| Sharpe {valid_split*\"Valid\" + (1 - valid_split)*\"Test\"} = ', sharpe)\n",
    "                        print('---')\n",
    "        print('------')\n",
    "        print(df_name)\n",
    "        print('Seed average no forecast = ', np.mean(sharpe_forecastFalse))\n",
    "        print('Seed average with forecast = ', np.mean(sharpe_forecastTrue))\n",
    "        print('------')\n",
    "        print('No forecast = ', sharpe_forecastFalse)\n",
    "        print('With forecast =', sharpe_forecastTrue)\n",
    "        print('------')\n",
    "    else:\n",
    "        print(\"RESUME TRAINING MODE\")\n",
    "        for seed_value in (seed_values*fixed_seed + (1 - fixed_seed) * [1]):\n",
    "            if fixed_seed: set_seed(seed_value)\n",
    "            \n",
    "            is_forecast_list = [False]\n",
    "            if is_forecast != None: is_forecast_list.append(True)\n",
    "            for is_forecast in is_forecast_list:\n",
    "                \n",
    "                if is_forecast:\n",
    "                    state_space = state_space_forecasts\n",
    "                    INDICATORS = INDICATORS_FORECASTS\n",
    "                    train = train_forecasts\n",
    "                    trade = trade_forecasts\n",
    "                    if valid_split: valid = valid_forecasts\n",
    "                else:\n",
    "                    state_space = state_space_main\n",
    "                    INDICATORS = INDICATORS_MAIN\n",
    "                    train = train_main\n",
    "                    trade = trade_main\n",
    "                    if valid_split: valid = valid_main\n",
    "\n",
    "                env_kwargs = env_kwargs_reinit()        \n",
    "                \n",
    "                k = 0\n",
    "                for i in range(start_training_episode,end_training_episode,step_training_episodes):\n",
    "                    NUM_EPISODES = i \n",
    "                    EPISODE_LENGTH = len(train)\n",
    "                    NUM_TRAINING_STEPS_FOR_1_TRIAL = NUM_EPISODES * EPISODE_LENGTH \n",
    "                    \n",
    "# STOPPED HERE ---------\n",
    "                    \n",
    "                    name_of_the_save_file = f\"{path_to_models}{model_name}_techindicators{dict_args['tech_indicators_usage']}_vix{dict_args['use_vix']}_turbulence{dict_args['use_turbulence']}\\\\{df_name}_{model_name}_lr{algorithm_parameters['learning_rate']}_Forecast{is_forecast}_Seed{str(seed_value)*fixed_seed + str(None)*(1-fixed_seed)}_Episodes{NUM_EPISODES}_Sharpe{valid_split*'Valid' + (1 - valid_split)*'Test'}{int(test_and_valid_pct*100)}\"\n",
    "                    name_of_the_save_file_zip = name_of_the_save_file + \".zip\"\n",
    "\n",
    "                    if not os.path.exists(name_of_the_save_file_zip):\n",
    "\n",
    "                        e_train_gym, env_train = env_reinit(train, env_kwargs_reinit())\n",
    "                        agent = DRLAgent(env = env_train)\n",
    "                        model = agent.get_model(model_name=model_name, model_kwargs = algorithm_parameters, verbose=0, seed=seed_value)\n",
    "\n",
    "                        if k > 0: model = trained\n",
    "                        else: model = agent.get_model(model_name=model_name, model_kwargs = algorithm_parameters, verbose=0, seed=seed_value)\n",
    "\n",
    "\n",
    "                        trained = agent.train_model(model=model, \n",
    "                                                        tb_log_name=model_name,\n",
    "                                                        total_timesteps=NUM_TRAINING_STEPS_FOR_1_TRIAL,\n",
    "                                                        callback=callback(chosen_callback)(callback_arg))\n",
    "\n",
    "                        if valid_split:\n",
    "                            if turbulence_threshold != None:\n",
    "                                env_trade_gym, env_trade = env_reinit(valid, env_kwargs_reinit(), turbulence_threshold_define(train, quantile), 'vix')\n",
    "                            else:\n",
    "                                env_trade_gym, env_trade = env_reinit(valid, env_kwargs_reinit())\n",
    "\n",
    "                        else: \n",
    "                            if turbulence_threshold != None:\n",
    "                                env_trade_gym, env_trade = env_reinit(trade, env_kwargs_reinit(), turbulence_threshold_define(train, quantile), 'vix')\n",
    "                            else:\n",
    "                                env_trade_gym, env_trade = env_reinit(trade, env_kwargs_reinit())\n",
    "\n",
    "                        df_account_value, df_actions = DRLAgent.prediction(\n",
    "                        model=trained, \n",
    "                        environment = env_trade_gym)\n",
    "\n",
    "                        sharpe = calculate_sharpe(df_account_value)\n",
    "\n",
    "                        trained.save(name_of_the_save_file_zip)\n",
    "\n",
    "                        print('Forecasts = ', is_forecast, '| Seed = ', seed_value, '| Num episodes = ', i, f'| Sharpe {valid_split*\"Valid\" + (1 - valid_split)*\"Test\"} = ', sharpe)\n",
    "                        print('---')\n",
    "\n",
    "                        k+=1\n",
    "                    else:\n",
    "                        k+=1\n",
    "\n",
    "                        print('Model already exists')\n",
    "\n",
    "                        e_train_gym, env_train = env_reinit(train, env_kwargs_reinit())\n",
    "                        agent = DRLAgent(env = env_train)\n",
    "                        model = agent.get_model(model_name=model_name, model_kwargs = algorithm_parameters, verbose=0, seed=seed_value)\n",
    "                        trained = model.load(name_of_the_save_file, env = env_train)\n",
    "\n",
    "                        if valid_split:\n",
    "                            if turbulence_threshold_usage:\n",
    "                                env_trade_gym, env_trade = env_reinit(valid, env_kwargs_reinit(), turbulence_threshold_define(train, quantile), 'vix')\n",
    "                            else:\n",
    "                                env_trade_gym, env_trade = env_reinit(valid, env_kwargs_reinit())\n",
    "\n",
    "                        else: \n",
    "                            if turbulence_threshold_usage:\n",
    "                                env_trade_gym, env_trade = env_reinit(trade, env_kwargs_reinit(), turbulence_threshold_define(train, quantile), 'vix')\n",
    "                            else:\n",
    "                                env_trade_gym, env_trade = env_reinit(trade, env_kwargs_reinit())\n",
    "\n",
    "\n",
    "                        df_account_value, df_actions = DRLAgent.prediction(\n",
    "                                                                                model=trained, \n",
    "                                                                                environment = env_trade_gym)\n",
    "                        sharpe = calculate_sharpe(df_account_value)\n",
    "                        print('Forecasts = ', is_forecast, '| Seed = ', seed_value, '| Num episodes = ', i, f'| Sharpe {valid_split*\"Valid\" + (1 - valid_split)*\"Test\"} = ', sharpe)\n",
    "                        print('---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
